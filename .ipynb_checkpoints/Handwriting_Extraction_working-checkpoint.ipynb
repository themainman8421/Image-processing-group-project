{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Extraction\n",
    "\n",
    "\n",
    "## Group members\n",
    "- Monika Adamczewska C17313136\n",
    "- James Behan C17348016\n",
    "- Conor Rogers C16347693\n",
    "\n",
    "\n",
    "# Description \n",
    "The purpose of this project is to extract and enhance text from images of handwriting on pages.   \n",
    "The user is prompted to choose an image that will be used to extract the handwritten text.   \n",
    "The image is loaded and the program will check if it has loaded correctly   \n",
    "    - If it has not loaded correctly an error is displayed to the user  \n",
    "    - If it has loaded correctly the program will continue with the code  \n",
    "A copy of the original image is stored - this will be used later to display the original image to the user   \n",
    "The image is converted to Grayscale and any streaks of bright light are removed. A mask is created this way   \n",
    "This mask is then inverted.  \n",
    "A new image is created by combining the Grayscale image and the inverted mask.  \n",
    "This new image is then inverted.   \n",
    "A check is put in place to make sure that the inverted image (which will serve as a mask) returns a result[1]  \n",
    "    - If all of the pixels in the inverted image are black an error is displayed to the user. This implies that the program could not find any handwritten text in the image   \n",
    "    - Otherwise the program will continue with the code  \n",
    "Morphology is then applied to the inverted image - this allows the program to extract a more precise region of interest  \n",
    "Thresholding and Morphology are used to filter out both the horizontal and the vertical lines from the page.[2]  \n",
    "A new mask is created and inverted - then used to remove the lines from the image so that a new Region of Interest is created.  \n",
    "Thresholding and Morphology are applied to this new Region of Interest to filter out the handwritten text as efficiently as possible.   \n",
    "A blank white image is then created[3]. This will be used as a background for the extracted handwritten text.   \n",
    "The blank image and the original image are then combined.   \n",
    "This combined image is converted to the HSV colourspace and the Volume channel is extracted.   \n",
    "The program then iterates through the Volume channel and darkens areas of the image to enhance the handwritten text.[4]  \n",
    "The enhanced image is stored and converted into the BGR colour space to allow for combining with the image of text on the white background.   \n",
    "These images are then combined to create a final image.   \n",
    "The original and final images are displayed to the user.  \n",
    "\n",
    "\n",
    "# Method\n",
    "1. Load the image\n",
    "2. Check if image has loaded correctly\n",
    "    * If not loaded correctly - display an error\n",
    "    * If loaded correctly - continue with the code\n",
    "3. Create a copy of the image\n",
    "4. Convert the image to grayscale\n",
    "5. Remove any streaks of bright light by applying morphology - this creates a mask\n",
    "6. Invert the mask\n",
    "7. Create a new image by combining the grayscale image and the inverted mask\n",
    "8. Invert this new image\n",
    "9. Check if the inverted image contains any parts of the original image\n",
    "    * If all of the pixels in the inverted image are black - display an error\n",
    "    * If there are pixels in the inverted image that are not black - continue with code\n",
    "10. Apply morphology to the inverted image to acquire a more precise region of interest\n",
    "11. Use thresholding and morphology to filter out the horizontal lines from the page\n",
    "12. Use thresholding and morphology to filter out the vertical lines from the page\n",
    "13. Combine the acquired line masks into one \n",
    "14. Invert the line mask\n",
    "15. Remove the lines from the original mask so that they do not interfere with the handwritten text - this creates a region of interest for inspection\n",
    "16. Apply thresholding and morphology to this region of interest to filter out the text from the image\n",
    "17. Create a blank white image - this will be used to as background of the filtered handwritten text\n",
    "18. Combine the blank image with the original image by using the numpy where function\n",
    "19. Convert this combined image to the HSV colourspace\n",
    "20. Extract the Value channel by splitting the HSV image\n",
    "21. Iterate through all of the pixels in the Value channel image\n",
    "    * If the pixel is not white, darken it by 100 and store in a new enhanced image\n",
    "22. Convert the new enhanced image to BGR to allow for combining it with the image that has the text on a white background\n",
    "23. Create a final image by combining the enhanced image with the image of the text on white background\n",
    "24. Display the original and the final images to the user \n",
    "\n",
    "\n",
    "# Testing\n",
    "The code was tested using various different images of handwriting.    \n",
    "Images of text written in blue pen as well as black pen were tested.\n",
    "Images with different lighting conditions were tested.\n",
    "\n",
    "# Conclusion \n",
    "Using methods mentioned in the outline above (thresholding, accessing individual channels within colour spaces[5], morphology) proved beneficial and was able to provide satisfying, though not ideal results.\n",
    "The main issue was not being able to extract all of the lines and edges from the image completely. Small parts of the lines from the copy are still visible on the final output image.\n",
    "\n",
    "# References\n",
    "\n",
    "[1]V. Valente, \"How to detect a full black color image in OpenCV Python?\", Stack Overflow, 2020. [Online]. Available: https://stackoverflow.com/questions/41406547/how-to-detect-a-full-black-color-image-in-opencv-python/41414865. \n",
    "\n",
    "[2]M. Maisonneuve, \"How to get the cells of a sudoku grid with OpenCV?\", Stack Overflow, 2020. [Online]. Available: https://stackoverflow.com/questions/59182827/how-to-get-the-cells-of-a-sudoku-grid-with-opencv.\n",
    "\n",
    "[3]Y. Yazıcıoğlu, \"Is it possible to paste an image on top of another in OpenCV?\", Stack Overflow, 2020. [Online]. Available: https://stackoverflow.com/questions/60937583/is-it-possible-to-paste-an-image-on-top-of-another-in-opencv.\n",
    "\n",
    "[4]\"Image Enhancement Techniques using OpenCV and Python\", Medium, 2020. [Online]. Available: https://towardsdatascience.com/image-enhancement-techniques-using-opencv-and-python-9191d5c30d45.\n",
    "\n",
    "[5]\"Color spaces in OpenCV (C++ / Python)\", Learnopencv.com, 2020. [Online]. Available: https://www.learnopencv.com/color-spaces-in-opencv-cpp-python/. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # The OpenCV library; install using `pip install opencv-contrib-python`\n",
    "import numpy as np # Helpful when working with arrays; install using `pip install numpy`\n",
    "from matplotlib import pyplot as plt # Good for graphing; install using `pip install matplotlib`\n",
    "from matplotlib import image as image\n",
    "import easygui # An easy-to-use file-picker; pip install easygui\n",
    "\n",
    "f = easygui.fileopenbox(filetypes=[\"*.jpg\",\"*.jpeg\",\"*.png\"])\n",
    "I = cv2.imread(f)\n",
    "\n",
    "# Error checking to see if the image was loaded correctly\n",
    "if I is None:\n",
    "    print('Invalid input')\n",
    "    sys.exit(0)\n",
    "else:\n",
    "    Original = I.copy()\n",
    "    #Converting the image to grayscale and removing any bright light streaks \n",
    "    Gray = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "    shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))\n",
    "    closed = cv2.morphologyEx(Gray,cv2.MORPH_CLOSE, shape, iterations=2)\n",
    "    inverted_mask = cv2.bitwise_not(closed)\n",
    "    new_image = Gray + inverted_mask\n",
    "\n",
    "    inverted_image = cv2.bitwise_not(new_image)\n",
    "\n",
    "    #Checking if the mask has returned any part of the image.\n",
    "    #If no text was found, an error message is displayed\n",
    "    if cv2.countNonZero(inverted_image) == 0:\n",
    "        print (\"Could not find handwritten text in image\")\n",
    "        sys.exit(0)\n",
    "    else:\n",
    "        #Applying morphology to the mask\n",
    "        shape = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(4,8))\n",
    "        new_mask = cv2.morphologyEx(inverted_image, cv2.MORPH_CLOSE,shape)   \n",
    "        \n",
    "        #Using thresholding and morphology to filter out the horizontal lines\n",
    "        T,horizontal_lines = cv2.threshold(new_mask,thresh=10,maxval=255,type = cv2.THRESH_BINARY)\n",
    "        shape = cv2.getStructuringElement(cv2.MORPH_RECT,(160,1))\n",
    "        horizontal_lines = cv2.morphologyEx(horizontal_lines, cv2.MORPH_OPEN,shape)\n",
    "        \n",
    "        #Using thresholding and morphology to filter out the vertical lines\n",
    "        T,vertical_lines = cv2.threshold(new_mask,thresh=10,maxval=255,type = cv2.THRESH_BINARY)\n",
    "        shape = cv2.getStructuringElement(cv2.MORPH_RECT,(1,160))\n",
    "        vertical_lines = cv2.morphologyEx(vertical_lines, cv2.MORPH_OPEN,shape)\n",
    "        \n",
    "        #Creating a combined mask for the vertical and horizontal lines\n",
    "        Lines = vertical_lines + horizontal_lines\n",
    "        Inverted_Lines = cv2.bitwise_not(Lines)\n",
    "        \n",
    "        #Removing the lines from the original mask to get a more accurate mask of the handwritten text\n",
    "        ROI = cv2.bitwise_and(inverted_image, inverted_image, mask = Inverted_Lines)\n",
    "\n",
    "        #Applying thresholding and morphology to filter out the text from the image\n",
    "        T,Text = cv2.threshold(ROI, thresh = 50, maxval = 255, type = cv2.THRESH_BINARY)\n",
    "        shape = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))\n",
    "        Text = cv2.dilate(Text,shape, iterations = 2)\n",
    "        Text = cv2.cvtColor(Text, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        #Creating a blank white image for the background\n",
    "        white = np.full_like(I, (255,255,255))\n",
    "\n",
    "        #Applying a mask to the original image and the blank white image\n",
    "        textOnWhite = np.where(Text!=0, I, white)\n",
    "        \n",
    "        plt.title(\"result\")\n",
    "        plt.imshow(result)\n",
    "        plt.show()\n",
    "        \n",
    "        #Converting the result image to HSV\n",
    "        HSV = cv2.cvtColor(textOnWhite,cv2.COLOR_BGR2HSV)\n",
    "        h,s,v = cv2.split(HSV)\n",
    "\n",
    "        #Enhancing the output image\n",
    "        for y in range(v.shape[0]):\n",
    "            for x in range(v.shape[1]):\n",
    "                if all(v[y,x] != [255,255,255]):\n",
    "                    v[y][x] = v[y][x] - 100\n",
    "                    enhancedImage = v\n",
    "        enhancedImage = cv2.cvtColor(enhancedImage, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        #Creating the final enhanced image\n",
    "        FinalImage = cv2.bitwise_and(enhancedImage,textOnWhite)\n",
    "        \n",
    "        #Displayig the original and the processed images to the user\n",
    "        plt.title(\"Original\")\n",
    "        plt.imshow(Original)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(\"Final Image\")\n",
    "        plt.imshow(FinalImage,cmap=\"gray\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
